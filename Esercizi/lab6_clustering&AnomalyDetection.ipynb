{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34bd005",
   "metadata": {},
   "source": [
    "# Unsupervised ML - Clustering and Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "137f6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from utils import generate_blobs_dataset, centroids_animation\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedac75d",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae42233",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4aa2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1) \n",
    "\n",
    "def pairwise_distance(X, centroids):\n",
    "    pairwise_dist = np.zeros((X.shape[0], centroids.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(centroids.shape[0]):\n",
    "            pairwise_dist[i, j] = np.linalg.norm(X[i] - centroids[j])\n",
    "\n",
    "    return pairwise_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5dcff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansClustering:\n",
    "    def __init__(self, n_clusters:int, max_iters:int=100, tol:float=1e-6):\n",
    "        self.k = n_clusters\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "        self.labels_ = None         # here we store the labels for the training point\n",
    "        self.history = []           # here we store the history of centroids\n",
    "\n",
    "    def _assign_clusters(self, X):\n",
    "        distances = pairwise_distance(X, self.centroids)\n",
    "        clusters = np.argmin(distances, axis=1)\n",
    "        return clusters\n",
    "    \n",
    "    def _update_centroids(self, X, labels):\n",
    "        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(self.k)])\n",
    "        return new_centroids\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.history = []\n",
    "        self.labels_history = []\n",
    "\n",
    "        # centroidi inizializzati random all'inizio\n",
    "        self.centroids = X[np.random.choice(X.shape[0], self.k, replace=False)]\n",
    "        labels = self._assign_clusters(X)\n",
    "\n",
    "        self.history.append(self.centroids.copy())\n",
    "        self.labels_history.append(labels.copy())\n",
    "\n",
    "        for _ in range(self.max_iters):\n",
    "            new_centroids = self._update_centroids(X, labels)\n",
    "            if np.all(np.abs(new_centroids - self.centroids) < self.tol):\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "            labels = self._assign_clusters(X)\n",
    "\n",
    "            self.history.append(self.centroids.copy())\n",
    "            self.labels_history.append(labels.copy())\n",
    "        \n",
    "        self.labels_ = labels\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5474ea",
   "metadata": {},
   "source": [
    "#### Determine the optimal number of cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELBOW METHOD\n",
    "\n",
    "def Wk(X, labels, centroids):\n",
    "    n_clusters = centroids.shape[0]\n",
    "    Wk = np.zeros(n_clusters)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        Wk[i] = np.sum((X[labels == i] - centroids[i]) ** 2)\n",
    "\n",
    "    return np.sum(Wk)\n",
    "\n",
    "def Wk_means(X, k_range, wkmean_list):\n",
    "    # Plot the Wk for each k\n",
    "    _, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot the Wk for each k\n",
    "    axes[0].plot(k_range, wkmean_list, marker=\"o\")\n",
    "    axes[0].set_title(\"W_k for Different Values of k\")\n",
    "    axes[0].set_xlabel(\"Number of Clusters (k)\")\n",
    "    axes[0].set_ylabel(\"W_k\")\n",
    "    axes[0].set_xticks(k_range)\n",
    "    axes[0].grid()\n",
    "\n",
    "    # Scatter plot of the data\n",
    "    axes[1].scatter(X[:, 0], X[:, 1], s=10, alpha=0.7)\n",
    "    axes[1].set_title(\"Scatter Plot of the Data\")\n",
    "    axes[1].set_xlabel(\"Feature 1\")\n",
    "    axes[1].set_ylabel(\"Feature 2\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAP STATISTIC\n",
    "\n",
    "def generate_reference_dataset(n_samples, n_features, lower_bound, upper_bound):\n",
    "    return np.random.uniform(lower_bound, upper_bound, size=(n_samples, n_features))\n",
    "\n",
    "def optimal_k_with_gap(X, klist, n_ref_dataset=10):\n",
    "    n_samples, n_features = X.shape\n",
    "    lower_bounds = [np.min(X[:, i]) for i in range(n_features)]\n",
    "    upper_bounds = [np.max(X[:, i]) for i in range(n_features)]\n",
    "\n",
    "    # 1) genero il dataset di riferimento \n",
    "    ref_datasets = [generate_reference_dataset(n_samples, n_features, lower_bounds, upper_bounds) for _ in range(n_ref_datasets)]\n",
    "    \n",
    "    gap_list = []\n",
    "    # 2) itero su k\n",
    "    for k in klist:\n",
    "        # Step 2.1 Fit k-means on our data using k clusters\n",
    "        np.random.seed(4)  # this is a horrible thing to ensure 'proper' centroids... just for the sake of the example!\n",
    "        kmeans = KMeansClustering(n_clusters=k)\n",
    "        kmeans.fit(X)\n",
    "        Wk = compute_Wk(X, kmeans.labels_, kmeans.centroids)\n",
    "\n",
    "        # Step 2.2 Fit k-means on each reference dataset using k clusters\n",
    "        Wk_ref = []\n",
    "        for X_ref in ref_datasets:\n",
    "            kmeans_ref = KMeansClustering(n_clusters=k)\n",
    "            kmeans_ref.fit(X_ref)\n",
    "            Wk_ref.append(compute_Wk(X_ref, kmeans_ref.labels_, kmeans_ref.centroids))\n",
    "\n",
    "        # compute gap statistic\n",
    "        log_Wk_rf = np.log(Wk_ref)\n",
    "        gap = np.mean(np.log(Wk_ref)) - np.log(Wk)\n",
    "        gap_list.append(gap)\n",
    "        print(f\"Gap statistic for k={k}: {gap}\")\n",
    "\n",
    "\n",
    "    # Step 3: select optimal k\n",
    "    std_logWk_ref = np.std(log_Wk_rf, axis=0)          # shape (n_ref_datasets, ). Std of each Wk_ref across datasets\n",
    "    upper_bound = gap_list - std_logWk_ref             # upper bound for the gap statistic\n",
    "\n",
    "    # take the minimum k for which gap(k) > upper_bound   optimal_k = None\n",
    "    optimal_k = None\n",
    "    for i in range(len(gap_list)-1):\n",
    "        if gap_list[i] >= upper_bound[i+1]:\n",
    "            optimal_k = klist[i]\n",
    "            break\n",
    "    if optimal_k == None:\n",
    "        optimal_k = klist[-1] # fallback\n",
    "        print(f\"Warning: optimal k not found. Using k={optimal_k}\")\n",
    "\n",
    "    return optimal_k, gap_list, std_logWk_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5020b3",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf92193",
   "metadata": {},
   "source": [
    "## Hotelling T^2 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409f770",
   "metadata": {},
   "source": [
    "#### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bded54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.normal(size=(100))\n",
    "\n",
    "mean = np.mean(X)\n",
    "var = np.var(X)\n",
    "\n",
    "outlier = np.array([5])\n",
    "\n",
    "distance = (outlier - mean)**2 / var\n",
    "print(f\"Distance of outlier from mean: {distance}\")\n",
    "\n",
    "# scatter plot\n",
    "plt.scatter(X, [0]*len(X), alpha=0.3, label='Normal Data')\n",
    "plt.scatter(outlier, [0], color='red', alpha=0.6, label='Outlier')\n",
    "plt.axvline(x=mean, color='green', linestyle='--', label='Estimated Mean')\n",
    "sns.kdeplot(X, bw_adjust=0.5, fill=True, alpha=0.2, label='KDE')\n",
    "plt.ylim(-0.2, 0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f95d84",
   "metadata": {},
   "source": [
    "#### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd51e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
